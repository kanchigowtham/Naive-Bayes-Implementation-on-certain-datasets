{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aggvHPt36_0V",
        "outputId": "50004527-5096-437b-985e-eebf7ea8e10a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "car_evaluation Dataset:\n",
            "Scores: [0.7732558139534884, 0.7732558139534884, 0.7441860465116279, 0.7616279069767442, 0.6976744186046512, 0.7093023255813954, 0.6337209302325582, 0.5232558139534884, 0.622093023255814, 0.46511627906976744]\n",
            "Mean Accuracy: 67.035%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#CSE-6363-002-MACHINE LEARNING\n",
        "#Gowtham Kumar Kanchi\n",
        "#1002044003 \n",
        "\n",
        "\n",
        "\n",
        "# Naive Bayes On The Iris Dataset\n",
        "from csv import reader\n",
        "from random import seed\n",
        "from random import randrange\n",
        "from math import sqrt\n",
        "from math import exp\n",
        "from math import pi\n",
        "import csv\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "from typing import List, Tuple\n",
        "def load_data(filename):\n",
        "    with open(filename, 'r') as file:\n",
        "        return [row for row in csv.reader(file) if row]\n",
        "\n",
        "\n",
        "def convert_column_to_float(data_list, col_idx):\n",
        "    for sample in data_list:\n",
        "        value_str = sample[col_idx].strip()\n",
        "        sample[col_idx] = float(value_str)\n",
        "\n",
        "def convert_column_to_integer(data, column_index):\n",
        "    class_mapping = defaultdict(int)\n",
        "    for sample in data:\n",
        "        value = sample[column_index]\n",
        "        if value not in class_mapping:\n",
        "            class_mapping[value] = len(class_mapping)\n",
        "        sample[column_index] = class_mapping[value]\n",
        "    return dict(class_mapping)\n",
        "\n",
        "\n",
        "def convert_col_to_int_car(dataset, col_idx):\n",
        "    for row in dataset:\n",
        "        value = row[col_idx].strip()\n",
        "        if value == 'more' or value == '5more':\n",
        "            row[col_idx] = 5\n",
        "        else:\n",
        "            row[col_idx] = int(value)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def split_data_into_folds(data, num_folds):\n",
        "    np.random.shuffle(data)\n",
        "    fold_size = len(data) // num_folds\n",
        "    folds_list = [data[i*fold_size:(i+1)*fold_size] for i in range(num_folds)]\n",
        "    return folds_list\n",
        "\n",
        "\n",
        "def calculate_accuracy(true_labels, predicted_labels):\n",
        "    num_correct = sum([1 for true, pred in zip(true_labels, predicted_labels) if true == pred])\n",
        "    return num_correct / len(true_labels) * 100\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_algorithm(data: List[List], algorithm: callable, num_folds: int, *args) -> List[float]:\n",
        "    def split_data_into_folds(data: List[List], num_folds: int) -> List[Tuple[List[List], List[List]]]:\n",
        "        n_rows = len(data)\n",
        "        fold_size = n_rows // num_folds\n",
        "        folds = []\n",
        "        for i in range(num_folds):\n",
        "            start = i * fold_size\n",
        "            end = start + fold_size\n",
        "            fold = (data[:start] + data[end:], data[start:end])\n",
        "            folds.append(fold)\n",
        "        return folds\n",
        "\n",
        "    def calculate_accuracy(actual: List, predicted: List) -> float:\n",
        "        num_correct = sum(1 for a, p in zip(actual, predicted) if a == p)\n",
        "        return num_correct / len(actual)\n",
        "\n",
        "    scores = []\n",
        "    for train_data, test_data in split_data_into_folds(data, num_folds):\n",
        "        predicted = algorithm(train_data, test_data, *args)\n",
        "        actual = [row[-1] for row in test_data]\n",
        "        accuracy = calculate_accuracy(actual, predicted)\n",
        "        scores.append(accuracy)\n",
        "    return scores\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Split the dataset by class values, returns a dictionary\n",
        "def separate_by_class(dataset):\n",
        "\tseparated = dict()\n",
        "\tfor i in range(len(dataset)):\n",
        "\t\tvector = dataset[i]\n",
        "\t\tclass_value = vector[-1]\n",
        "\t\tif (class_value not in separated):\n",
        "\t\t\tseparated[class_value] = list()\n",
        "\t\tseparated[class_value].append(vector)\n",
        "\treturn separated\n",
        "\n",
        "# Calculate the mean of a list of numbers\n",
        "def calculate_mean(numbers):\n",
        "\treturn sum(numbers)/float(len(numbers))\n",
        "\n",
        "# Calculate the standard deviation of a list of numbers\n",
        "def calculate_std_dev(numbers):\n",
        "    avg_num = calculate_mean(numbers)\n",
        "    var_sum = sum([(x - avg_num) ** 2 for x in numbers]) / float(len(numbers) - 1)\n",
        "    return sqrt(var_sum)\n",
        "\n",
        "# Calculate the mean, standard deviation and count for each column in a dataset\n",
        "def summarize_data(dataset):\n",
        "    data_summary = [(calculate_mean(column), calculate_std_dev(column), len(column)) for column in zip(*dataset)]\n",
        "    del data_summary[-1]\n",
        "    return data_summary\n",
        "\n",
        "# Split dataset by class then calculate statistics for each row\n",
        "def summarize_by_class(dataset):\n",
        "    class_dict = separate_by_class(dataset)\n",
        "    class_summary = {}\n",
        "    for class_val, rows in class_dict.items():\n",
        "        class_summary[class_val] = summarize_data(rows)\n",
        "    return class_summary\n",
        "\n",
        "# Calculate the Gaussian probability distribution function for x\n",
        "def calculate_prob_distribution(x, mean, std_dev):\n",
        "    exponent = exp(-((x - mean) ** 2 / (2 * std_dev ** 2)))\n",
        "    return (1 / (sqrt(2 * pi) * std_dev)) * exponent\n",
        "\n",
        "def calculate_class_probabilities(class_summary, row):\n",
        "    total_rows = 0\n",
        "    class_count = {}\n",
        "    for class_val in class_summary:\n",
        "        class_count[class_val] = 0\n",
        "        for i in range(len(class_summary[class_val])):\n",
        "            class_count[class_val] += class_summary[class_val][i][2]\n",
        "            total_rows += class_summary[class_val][i][2]\n",
        "    class_probabilities = {}\n",
        "    for class_val in class_summary:\n",
        "        class_probability = 1\n",
        "        for i in range(len(class_summary[class_val])):\n",
        "            mean_val, std_dev_val, _ = class_summary[class_val][i]\n",
        "            x = row[i]\n",
        "            if std_dev_val == 0:\n",
        "                if x != mean_val:\n",
        "                    class_probability = 0\n",
        "                    break\n",
        "            else:\n",
        "                numerator = 1\n",
        "                denominator = sqrt(2*pi)*std_dev_val\n",
        "                exponent = -1/2 * ((x-mean_val)/std_dev_val)**2\n",
        "                probability_density = numerator/denominator * exp(exponent)\n",
        "                class_probability *= probability_density\n",
        "        class_probability *= class_count[class_val]/total_rows\n",
        "        class_probabilities[class_val] = class_probability\n",
        "    return class_probabilities\n",
        "\n",
        "\n",
        "\n",
        "def predict_class(summaries, row):\n",
        "    class_probabilities = calculate_class_probabilities(summaries, row)\n",
        "    best_label = max(class_probabilities, key=class_probabilities.get)\n",
        "    return best_label\n",
        "\n",
        "\n",
        "def naive_bayes(train_set, test_set):\n",
        "    summaries = summarize_by_class(train_set)\n",
        "    predictions = [predict_class(summaries, row) for row in test_set]\n",
        "    return predictions\n",
        "\n",
        "seed(1)\n",
        "filename = 'car_evaluation.csv'\n",
        "dataset = load_data(filename)\n",
        "\n",
        "\n",
        "if filename == 'breast_cancer.csv':\n",
        "    for column_index in range(len(dataset[0])):\n",
        "        class_mapping = convert_column_to_integer(dataset, column_index)\n",
        "if filename == 'car_evaluation.csv':\n",
        "    for sample in dataset:\n",
        "        del sample[5]\n",
        "    for column_index in range(2, 4):\n",
        "        convert_col_to_int_car(dataset, column_index)\n",
        "    for column_index in range(len(dataset[0])):\n",
        "        if column_index not in (2, 3):\n",
        "            class_mapping = convert_column_to_integer(dataset, column_index)\n",
        "if filename == 'hayes_r.csv':\n",
        "    for column_index in range(len(dataset[0])-1):\n",
        "        convert_column_to_float(dataset, column_index)\n",
        "    class_mapping = convert_column_to_integer(dataset, len(dataset[0])-1)\n",
        "\n",
        "# evaluate algorithm\n",
        "n_folds = 10\n",
        "scores = evaluate_algorithm(dataset, naive_bayes, n_folds)\n",
        "print(\"car_evaluation Dataset:\")\n",
        "print('Scores: %s' % scores)\n",
        "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWIFhe-a6zm_",
        "outputId": "84571be1-50ea-42dc-851f-b03db1536c7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Breast_Cancer Dataset:\n",
            "Scores: [1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.4642857142857143, 0.6428571428571429, 0.8214285714285714, 0.5, 0.4642857142857143]\n",
            "Mean Accuracy: 77.500%\n"
          ]
        }
      ],
      "source": [
        "#CSE-6363-002-MACHINE LEARNING\n",
        "#Gowtham Kumar Kanchi\n",
        "#1002044003 \n",
        "\n",
        "# Naive Bayes On The Iris Dataset\n",
        "from csv import reader\n",
        "from random import seed\n",
        "from random import randrange\n",
        "from math import sqrt\n",
        "from math import exp\n",
        "from math import pi\n",
        "import csv\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "from typing import List, Tuple\n",
        "def load_data(filename):\n",
        "    with open(filename, 'r') as file:\n",
        "        return [row for row in csv.reader(file) if row]\n",
        "\n",
        "\n",
        "def convert_column_to_float(data_list, col_idx):\n",
        "    for sample in data_list:\n",
        "        value_str = sample[col_idx].strip()\n",
        "        sample[col_idx] = float(value_str)\n",
        "\n",
        "def convert_column_to_integer(data, column_index):\n",
        "    class_mapping = defaultdict(int)\n",
        "    for sample in data:\n",
        "        value = sample[column_index]\n",
        "        if value not in class_mapping:\n",
        "            class_mapping[value] = len(class_mapping)\n",
        "        sample[column_index] = class_mapping[value]\n",
        "    return dict(class_mapping)\n",
        "\n",
        "\n",
        "def convert_col_to_int_car(dataset, col_idx):\n",
        "    for row in dataset:\n",
        "        value = row[col_idx].strip()\n",
        "        if value == 'more' or value == '5more':\n",
        "            row[col_idx] = 5\n",
        "        else:\n",
        "            row[col_idx] = int(value)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def split_data_into_folds(data, num_folds):\n",
        "    np.random.shuffle(data)\n",
        "    fold_size = len(data) // num_folds\n",
        "    folds_list = [data[i*fold_size:(i+1)*fold_size] for i in range(num_folds)]\n",
        "    return folds_list\n",
        "\n",
        "\n",
        "def calculate_accuracy(true_labels, predicted_labels):\n",
        "    num_correct = sum([1 for true, pred in zip(true_labels, predicted_labels) if true == pred])\n",
        "    return num_correct / len(true_labels) * 100\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_algorithm(data: List[List], algorithm: callable, num_folds: int, *args) -> List[float]:\n",
        "    def split_data_into_folds(data: List[List], num_folds: int) -> List[Tuple[List[List], List[List]]]:\n",
        "        n_rows = len(data)\n",
        "        fold_size = n_rows // num_folds\n",
        "        folds = []\n",
        "        for i in range(num_folds):\n",
        "            start = i * fold_size\n",
        "            end = start + fold_size\n",
        "            fold = (data[:start] + data[end:], data[start:end])\n",
        "            folds.append(fold)\n",
        "        return folds\n",
        "\n",
        "    def calculate_accuracy(actual: List, predicted: List) -> float:\n",
        "        num_correct = sum(1 for a, p in zip(actual, predicted) if a == p)\n",
        "        return num_correct / len(actual)\n",
        "\n",
        "    scores = []\n",
        "    for train_data, test_data in split_data_into_folds(data, num_folds):\n",
        "        predicted = algorithm(train_data, test_data, *args)\n",
        "        actual = [row[-1] for row in test_data]\n",
        "        accuracy = calculate_accuracy(actual, predicted)\n",
        "        scores.append(accuracy)\n",
        "    return scores\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Split the dataset by class values, returns a dictionary\n",
        "def separate_by_class(dataset):\n",
        "\tseparated = dict()\n",
        "\tfor i in range(len(dataset)):\n",
        "\t\tvector = dataset[i]\n",
        "\t\tclass_value = vector[-1]\n",
        "\t\tif (class_value not in separated):\n",
        "\t\t\tseparated[class_value] = list()\n",
        "\t\tseparated[class_value].append(vector)\n",
        "\treturn separated\n",
        "\n",
        "# Calculate the mean of a list of numbers\n",
        "def calculate_mean(numbers):\n",
        "\treturn sum(numbers)/float(len(numbers))\n",
        "\n",
        "# Calculate the standard deviation of a list of numbers\n",
        "def calculate_std_dev(numbers):\n",
        "    avg_num = calculate_mean(numbers)\n",
        "    var_sum = sum([(x - avg_num) ** 2 for x in numbers]) / float(len(numbers) - 1)\n",
        "    return sqrt(var_sum)\n",
        "\n",
        "# Calculate the mean, standard deviation and count for each column in a dataset\n",
        "def summarize_data(dataset):\n",
        "    data_summary = [(calculate_mean(column), calculate_std_dev(column), len(column)) for column in zip(*dataset)]\n",
        "    del data_summary[-1]\n",
        "    return data_summary\n",
        "\n",
        "# Split dataset by class then calculate statistics for each row\n",
        "def summarize_by_class(dataset):\n",
        "    class_dict = separate_by_class(dataset)\n",
        "    class_summary = {}\n",
        "    for class_val, rows in class_dict.items():\n",
        "        class_summary[class_val] = summarize_data(rows)\n",
        "    return class_summary\n",
        "\n",
        "# Calculate the Gaussian probability distribution function for x\n",
        "def calculate_prob_distribution(x, mean, std_dev):\n",
        "    exponent = exp(-((x - mean) ** 2 / (2 * std_dev ** 2)))\n",
        "    return (1 / (sqrt(2 * pi) * std_dev)) * exponent\n",
        "\n",
        "def calculate_class_probabilities(class_summary, row):\n",
        "    total_rows = 0\n",
        "    class_count = {}\n",
        "    for class_val in class_summary:\n",
        "        class_count[class_val] = 0\n",
        "        for i in range(len(class_summary[class_val])):\n",
        "            class_count[class_val] += class_summary[class_val][i][2]\n",
        "            total_rows += class_summary[class_val][i][2]\n",
        "    class_probabilities = {}\n",
        "    for class_val in class_summary:\n",
        "        class_probability = 1\n",
        "        for i in range(len(class_summary[class_val])):\n",
        "            mean_val, std_dev_val, _ = class_summary[class_val][i]\n",
        "            x = row[i]\n",
        "            if std_dev_val == 0:\n",
        "                if x != mean_val:\n",
        "                    class_probability = 0\n",
        "                    break\n",
        "            else:\n",
        "                numerator = 1\n",
        "                denominator = sqrt(2*pi)*std_dev_val\n",
        "                exponent = -1/2 * ((x-mean_val)/std_dev_val)**2\n",
        "                probability_density = numerator/denominator * exp(exponent)\n",
        "                class_probability *= probability_density\n",
        "        class_probability *= class_count[class_val]/total_rows\n",
        "        class_probabilities[class_val] = class_probability\n",
        "    return class_probabilities\n",
        "\n",
        "\n",
        "\n",
        "def predict_class(summaries, row):\n",
        "    class_probabilities = calculate_class_probabilities(summaries, row)\n",
        "    best_label = max(class_probabilities, key=class_probabilities.get)\n",
        "    return best_label\n",
        "\n",
        "\n",
        "def naive_bayes(train_set, test_set):\n",
        "    summaries = summarize_by_class(train_set)\n",
        "    predictions = [predict_class(summaries, row) for row in test_set]\n",
        "    return predictions\n",
        "\n",
        "seed(1)\n",
        "filename = 'breast_cancer.csv'\n",
        "dataset = load_data(filename)\n",
        "\n",
        "\n",
        "if filename == 'breast_cancer.csv':\n",
        "    for column_index in range(len(dataset[0])):\n",
        "        class_mapping = convert_column_to_integer(dataset, column_index)\n",
        "if filename == 'car_evaluation.csv':\n",
        "    for sample in dataset:\n",
        "        del sample[5]\n",
        "    for column_index in range(2, 4):\n",
        "        convert_col_to_int_car(dataset, column_index)\n",
        "    for column_index in range(len(dataset[0])):\n",
        "        if column_index not in (2, 3):\n",
        "            class_mapping = convert_column_to_integer(dataset, column_index)\n",
        "if filename == 'hayes_r.csv':\n",
        "    for column_index in range(len(dataset[0])-1):\n",
        "        convert_column_to_float(dataset, column_index)\n",
        "    class_mapping = convert_column_to_integer(dataset, len(dataset[0])-1)\n",
        "\n",
        "# evaluate algorithm\n",
        "n_folds = 10\n",
        "scores = evaluate_algorithm(dataset, naive_bayes, n_folds)\n",
        "print(\"Breast_Cancer Dataset:\")\n",
        "print('Scores: %s' % scores)\n",
        "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyyCCMjqdQ3S",
        "outputId": "e7bf4dbb-95dd-493e-cb53-373501bbcc46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hayes_r Dataset:\n",
            "Scores: [0.6923076923076923, 0.5384615384615384, 0.7692307692307693, 0.6153846153846154, 0.7692307692307693, 0.6153846153846154, 0.6923076923076923, 0.6923076923076923, 0.9230769230769231, 0.7692307692307693]\n",
            "Mean Accuracy: 70.769%\n"
          ]
        }
      ],
      "source": [
        "#CSE-6363-002-MACHINE LEARNING\n",
        "#Gowtham Kumar Kanchi\n",
        "#1002044003 \n",
        "\n",
        "\n",
        "\n",
        "# Naive Bayes On The Iris Dataset\n",
        "from csv import reader\n",
        "from random import seed\n",
        "from random import randrange\n",
        "from math import sqrt\n",
        "from math import exp\n",
        "from math import pi\n",
        "import csv\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "from typing import List, Tuple\n",
        "def load_data(filename):\n",
        "    with open(filename, 'r') as file:\n",
        "        return [row for row in csv.reader(file) if row]\n",
        "\n",
        "\n",
        "def convert_column_to_float(data_list, col_idx):\n",
        "    for sample in data_list:\n",
        "        value_str = sample[col_idx].strip()\n",
        "        sample[col_idx] = float(value_str)\n",
        "\n",
        "def convert_column_to_integer(data, column_index):\n",
        "    class_mapping = defaultdict(int)\n",
        "    for sample in data:\n",
        "        value = sample[column_index]\n",
        "        if value not in class_mapping:\n",
        "            class_mapping[value] = len(class_mapping)\n",
        "        sample[column_index] = class_mapping[value]\n",
        "    return dict(class_mapping)\n",
        "\n",
        "\n",
        "def convert_col_to_int_car(dataset, col_idx):\n",
        "    for row in dataset:\n",
        "        value = row[col_idx].strip()\n",
        "        if value == 'more' or value == '5more':\n",
        "            row[col_idx] = 5\n",
        "        else:\n",
        "            row[col_idx] = int(value)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def split_data_into_folds(data, num_folds):\n",
        "    np.random.shuffle(data)\n",
        "    fold_size = len(data) // num_folds\n",
        "    folds_list = [data[i*fold_size:(i+1)*fold_size] for i in range(num_folds)]\n",
        "    return folds_list\n",
        "\n",
        "\n",
        "def calculate_accuracy(true_labels, predicted_labels):\n",
        "    num_correct = sum([1 for true, pred in zip(true_labels, predicted_labels) if true == pred])\n",
        "    return num_correct / len(true_labels) * 100\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_algorithm(data: List[List], algorithm: callable, num_folds: int, *args) -> List[float]:\n",
        "    def split_data_into_folds(data: List[List], num_folds: int) -> List[Tuple[List[List], List[List]]]:\n",
        "        n_rows = len(data)\n",
        "        fold_size = n_rows // num_folds\n",
        "        folds = []\n",
        "        for i in range(num_folds):\n",
        "            start = i * fold_size\n",
        "            end = start + fold_size\n",
        "            fold = (data[:start] + data[end:], data[start:end])\n",
        "            folds.append(fold)\n",
        "        return folds\n",
        "\n",
        "    def calculate_accuracy(actual: List, predicted: List) -> float:\n",
        "        num_correct = sum(1 for a, p in zip(actual, predicted) if a == p)\n",
        "        return num_correct / len(actual)\n",
        "\n",
        "    scores = []\n",
        "    for train_data, test_data in split_data_into_folds(data, num_folds):\n",
        "        predicted = algorithm(train_data, test_data, *args)\n",
        "        actual = [row[-1] for row in test_data]\n",
        "        accuracy = calculate_accuracy(actual, predicted)\n",
        "        scores.append(accuracy)\n",
        "    return scores\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Split the dataset by class values, returns a dictionary\n",
        "def separate_by_class(dataset):\n",
        "\tseparated = dict()\n",
        "\tfor i in range(len(dataset)):\n",
        "\t\tvector = dataset[i]\n",
        "\t\tclass_value = vector[-1]\n",
        "\t\tif (class_value not in separated):\n",
        "\t\t\tseparated[class_value] = list()\n",
        "\t\tseparated[class_value].append(vector)\n",
        "\treturn separated\n",
        "\n",
        "# Calculate the mean of a list of numbers\n",
        "def calculate_mean(numbers):\n",
        "\treturn sum(numbers)/float(len(numbers))\n",
        "\n",
        "# Calculate the standard deviation of a list of numbers\n",
        "def calculate_std_dev(numbers):\n",
        "    avg_num = calculate_mean(numbers)\n",
        "    var_sum = sum([(x - avg_num) ** 2 for x in numbers]) / float(len(numbers) - 1)\n",
        "    return sqrt(var_sum)\n",
        "\n",
        "# Calculate the mean, standard deviation and count for each column in a dataset\n",
        "def summarize_data(dataset):\n",
        "    data_summary = [(calculate_mean(column), calculate_std_dev(column), len(column)) for column in zip(*dataset)]\n",
        "    del data_summary[-1]\n",
        "    return data_summary\n",
        "\n",
        "# Split dataset by class then calculate statistics for each row\n",
        "def summarize_by_class(dataset):\n",
        "    class_dict = separate_by_class(dataset)\n",
        "    class_summary = {}\n",
        "    for class_val, rows in class_dict.items():\n",
        "        class_summary[class_val] = summarize_data(rows)\n",
        "    return class_summary\n",
        "\n",
        "# Calculate the Gaussian probability distribution function for x\n",
        "def calculate_prob_distribution(x, mean, std_dev):\n",
        "    exponent = exp(-((x - mean) ** 2 / (2 * std_dev ** 2)))\n",
        "    return (1 / (sqrt(2 * pi) * std_dev)) * exponent\n",
        "\n",
        "def calculate_class_probabilities(class_summary, row):\n",
        "    total_rows = 0\n",
        "    class_count = {}\n",
        "    for class_val in class_summary:\n",
        "        class_count[class_val] = 0\n",
        "        for i in range(len(class_summary[class_val])):\n",
        "            class_count[class_val] += class_summary[class_val][i][2]\n",
        "            total_rows += class_summary[class_val][i][2]\n",
        "    class_probabilities = {}\n",
        "    for class_val in class_summary:\n",
        "        class_probability = 1\n",
        "        for i in range(len(class_summary[class_val])):\n",
        "            mean_val, std_dev_val, _ = class_summary[class_val][i]\n",
        "            x = row[i]\n",
        "            if std_dev_val == 0:\n",
        "                if x != mean_val:\n",
        "                    class_probability = 0\n",
        "                    break\n",
        "            else:\n",
        "                numerator = 1\n",
        "                denominator = sqrt(2*pi)*std_dev_val\n",
        "                exponent = -1/2 * ((x-mean_val)/std_dev_val)**2\n",
        "                probability_density = numerator/denominator * exp(exponent)\n",
        "                class_probability *= probability_density\n",
        "        class_probability *= class_count[class_val]/total_rows\n",
        "        class_probabilities[class_val] = class_probability\n",
        "    return class_probabilities\n",
        "\n",
        "\n",
        "\n",
        "def predict_class(summaries, row):\n",
        "    class_probabilities = calculate_class_probabilities(summaries, row)\n",
        "    best_label = max(class_probabilities, key=class_probabilities.get)\n",
        "    return best_label\n",
        "\n",
        "\n",
        "def naive_bayes(train_set, test_set):\n",
        "    summaries = summarize_by_class(train_set)\n",
        "    predictions = [predict_class(summaries, row) for row in test_set]\n",
        "    return predictions\n",
        "\n",
        "seed(1)\n",
        "filename = 'hayes_r.csv'\n",
        "dataset = load_data(filename)\n",
        "\n",
        "\n",
        "if filename == 'breast_cancer.csv':\n",
        "    for column_index in range(len(dataset[0])):\n",
        "        class_mapping = convert_column_to_integer(dataset, column_index)\n",
        "if filename == 'car_evaluation.csv':\n",
        "    for sample in dataset:\n",
        "        del sample[5]\n",
        "    for column_index in range(2, 4):\n",
        "        convert_col_to_int_car(dataset, column_index)\n",
        "    for column_index in range(len(dataset[0])):\n",
        "        if column_index not in (2, 3):\n",
        "            class_mapping = convert_column_to_integer(dataset, column_index)\n",
        "if filename == 'hayes_r.csv':\n",
        "    for column_index in range(len(dataset[0])-1):\n",
        "        convert_column_to_float(dataset, column_index)\n",
        "    class_mapping = convert_column_to_integer(dataset, len(dataset[0])-1)\n",
        "\n",
        "# evaluate algorithm\n",
        "n_folds = 10\n",
        "scores = evaluate_algorithm(dataset, naive_bayes, n_folds)\n",
        "print(\"Hayes_r Dataset:\")\n",
        "print('Scores: %s' % scores)\n",
        "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))*100))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
